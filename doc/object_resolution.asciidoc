[[object-resolution]]
== Object Resolution

The meat of a GraphQL system is the resolver for objects. You have a
concrete object on which you are resolving _fields_. As we shall see,
this is used for two kinds of things a client wants to do with the
graph.

.Raw Field Access

First, field resolution on objects are used because you have a loaded
object and the client has requested some specific fields on that
object. For example, you may have loaded a *Starship* and you might be
requesting the *name* of the Starship.

.Derived Field Access

Second, field resolution on objects is used to _derive_ values from
other values. Suppose a *Starship* had two fields internally
*cargoCapacity* and *cargoLoad*. We might want to compute the load
factor of the Starship as a value between 0.0 and 1.0. This amounts to
running the computation `CargoLoad / CargoCapacity`. Rather than
storing this value in the data, we can just compute it by derivation
if the client happens to request the field. Otherwise, we abstain from
computing it.

An advantage of derivation is that you can handle things lazily. Once
the client wants a field, you start doing the work for computing and
returning that field. Also, derivation improves data normalization in
many cases. Modern computers are fast and data fetches tend to be the
major part of a client request. A bit of computation before returning
data is rarely going to be dominant in the grand scheme of things.

.Data Fetching Field Access

Finally, field resolution on objects is used to _fetch_ objects from
a backend data store. Consider the field `node(id: ID!)` on the
`Query` object in the schema:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=queryObject]
----

When a `query` starts executing, an _initial_term_ is injected in by
the developer. By convention this object is often either `null` or
`#{}` signifying we currently have no current object. The reference to
the `node` field states that the client wants to load a _Node_ object.
So we fetch the given node from the database and return the data back
to GraphQL.

The GraphQL server now does two things:

* First, it recursively digs into the returned _Node_. It places its
  "`cursor`" on the Node and then it does <<type-resolution>> on the
  Node in order to make it concrete. This may uncover the Node is
  really a *Planet* and then the query proceeds by executing fields
  in the planet type. Once the recursion ends, we have constructed a
  `Response` for the `node` object.
* Next, it returns the underlying recursive response as a mapping
  `"node" => Response` and returns this for the field. Once every
  field on the top-level `Query` object has been satisfied, we have 
  our final response.

Hopefully it is clear that the field resolution here is used as a way
to load and fetch data. The same mechanism is used to "`follow`"
associations between data in the database, by lazily executing JOINs
on the database level.

TIP: It is also possible to return a whole subtree at once when a
field is resolved. This corresponds to eager/strict loading in an ORM
and is useful in the situation where you expect the client to request
the data with high probability, or when fetching the extra data is
done anyway. In this case, making the data available for further query
in the Graph is almost always beneficial. The price for fetching the
data has already been paid anyway. The implementation is simply to
make sure that recursive objects test if the data is already loaded.

=== Execution

We start with plain field access on the *Planet* and *Starship* types.
Our mapping rules have mapped `'Starship' => sw_core_starship` so the
field handling lives in the module `sw_core_starship`. Likewise, we
map `'Planet' => sw_core_planet` and so on. In general, object
resolution is handled by a single function, `execute/4`:

[source,erlang]
----
-spec execute(Ctx, Obj, Field, Args) ->
                {ok, Result} | {error, Reason}
  when
    Ctx :: context(), % <1>
    Obj :: term(), % <2>
    Field :: binary(), % <3>
    Args :: #{ binary() => term() } % <4>
    Result :: term(),
    Reason :: term().
----
<1> The current context set by the developer and derived from the
    position in the graph.
<2> The current object the cursor points to
<3> The field the client has requested
<4> The arguments to the field as a map

The function is called `execute` because it relates to the GraphQL
notion of executing a query on the server side. And because the word
"`execution`" maps precisely onto what you are doing. You are invoking
functions on the server side, relating to the query by the client.

In the following we give a detailed explanation of each of the fields
here and what their purpose are:

.Ctx

The <<context>> is a map which contains contextual information about
the query. Its primary purpose is that the developers can set data
into the context at the top-level when they start processing a GraphQL
query. In turn, the context is often stuffed with data from the
outside of the GraphQL system:

* User authentication information.
* The source IP address executing the query.
* What type of transport was used to initiate the query.
* Process `pid()` values for processes that pertain to this query.

Additionally, the context also contains some base information added by
the GraphQL system. Most notably the current object type and field.
This allows one to build some extremely generic `execute/4` functions
that handles large classes of objects.

TIP: Sizable graph schemas tend to contain a number of administrative
"`filler`" objects used to glue other objects together. These are
often possible to handle by a single default executor which looks at
the context in order to derive what to do with the particular object.
If a type becomes non-generic, you can then work gradually and shift
it to a specific `execute/4` handler for that particular object.

.Obj

The `Obj` field points to the current object we are rendering for,
e.g. a *Starship* given as the a value `#starship{...}`. This field is
the binding of a type to a concrete object we are working on. As an
example, a B-wing is a *Starship*, an X-wing is a *Starship*, and a
TIE-fighter is a *Starship*. So when the `execute/4` code runs, it
needs to know what concrete loaded object is in play. Another way of
seeing it is that the `Obj` is the object the <<cursor>> is currently
pointing at in the Graph Rendering.

.Field

The field is the current field which the client requested in the
object. The field is also inside the context, but because it is very
common it is also an argument to the function directly. The field
allows you to pattern match on different fields of the query.

.Args

The arguments are always of type `#{ binary() => term() }`; mapping
from field name to field value. If a client queries

[source,graphql]
----
query {
  node(id: "SOMEID") {
     __typename
     id
  }
}
----

then we will have `Args = #{ \<<"id">> => \<<"SOMEID">>}` and we
can proceed by pattern matching on this object.

[[input-argument-rules]]
=== Input argument rules

An important thing to cover at this point is how mappings of input
arguments are done in GraphQL. A GraphQL client has _no_ way of
inputting a `null` value. It is not allowed for the client to ever use
a `null` in any input position. Rather, the way a client specifies it
has no value, is by omission of a given input field.

The GraphQL system considers the omission of a field depending on the
configuration of that field:

* If the field has a default value, the field takes on the default
  value.
* If the field is non-null, the query is rejected. The client must
  supply a value for a non-null field.
* If the field has no default value, the mapping `Field => null`
  is added to the input map.

In short, an object resolution module can assume that _all_ fields are
always present in the `Args` map, either populated by a default value
or by a `null` value if that field has no default. It is a brilliant
design choice by the GraphQL specification designers: clients have one
unambiguous way to input "`no value`" and servers have one unambiguous
way of processing "`no value`".

TIP: Add sane defaults to your schema. If an input is a list, default
it to the empty list `[]`, such that your code can `lists:map/2` over
the input. But because the list is `[]` nothing happens. This can be
used to eliminate code paths in your code by using default values for
the data structures you are working on.

=== Handling Planets

In our system, we have a module `sw_core_planet` which handles the
execution parts of planets. Planets are rather simple objects in that
most of their internals are directly mapped to an underlying Mnesia
database. The `execute/4` function describes how the Mnesia records
are mapped into the GraphQL world of fields the client requested.

The only exported function is `execute/4` which we dissect a bit here.
We omit some parts which are not very interesting as of now:

[source,erlang]
----
include::{sw_core}/src/sw_core_planet.erl[tags=planetExecute]
...
----

In our case, since we are working with Mnesia data, we need a
projection function to take fields out of the record and return them
to the GraphQL system. Note that we can use this to rename fields. The
GraphQL specifies `rotationPeriod` whereas we use the Erlang idiomatic
internal name `rotation_period`.

If you think this is a lot of typing, you can choose to represent
Planets as a `map()` and then the execution function is basically

[source,erlang]
----
execute(Ctx, Obj, Field, Args) ->
    maps:get(Field, Obj, {ok, null}).
----

but the price you pay for doing so is that the names in the `Obj` has
to match the names in the GraphQL specification. In our experience, it
is often the case that things evolve and you need to rename fields. So
this is not always a desirable solution.

=== Handling Starships

When a *Starhip* is loaded from the database, remember from
<<interfaces-and-unions>> that we are loading a starship as two rows:
One for the transport part, which is shared with vehicles, and one for
the starship part which is unique to starships. This means that the
"`current object`" when field resolving on a starship is a pair of a
transport and a starship row. The resolver function must handle this,
by retrieving the field from either the transport or the starship.
This is easily done in the `execute/4` function:

[source,erlang]
----
include::{sw_core}/src/sw_core_starship.erl[tags=starshipExecute]
...
----

The example here exemplifies that a current object can be _any_ Erlang
term you like. The output from the GraphQL system is always being
mediated by an `execute/4` function, so as long as you can translate
from that Erlang term and into a valid field value, you are golden.

NOTE: An alternative implementation of the current object for
Starships would be to return a `map()` which had all the relevant
fields from the `#transport{}` and `#starship{}` rows merged. In
short, it would be the same as if you had executed `SELECT * FROM
Starship INNER JOIN Transport USING (Id)`. It is worth examining if a
different representation will help in a given situation.

==== Id handling

In our system, we need to turn an ID on the Mnesia side into an ID in
GraphQL. Luckily, we've already defined the ID encoder/decoder in the
section <<identity-generation>>, so we can simply utilize those
methods whenever we want to return an ID.

An alternative to the solution depicted here is to encode the ID
whenever you load the object from the underlying database; and then
undo that encoding whenever you store the object back. The best
solution depends on your preferences and where your API boundary
between the GraphQL contract and the database is.

=== Loading Data

Our *Planet* execute function handles the case where we have a
loaded planet and want to output its contents. But it doesn't say
anything about how to fetch a planet from the database. This section
handles the loading of data from Mnesia while running GraphQL queries.

The type *Query* in the GraphQL specification (see
<<queries-and-mutations>>) contains a field `node` and a field
`planet` which are used to load any node or a planet respectively.
The loader is the same, and `planet` is just a specialization of the
`node` loader.

Let us define the execution function for handling loading. We simply
extract the interesting data and forward our query to a plain Erlang
function:

[source,erlang]
----
include::{sw_core}/src/sw_core_query.erl[tags=execute]
...
----

The function which actually loads the object can now be written:

[source,erlang]
----
include::{sw_core}/src/sw_core_query.erl[tags=loadNode]
----

To load a particular node, we first attempt to decode the ID into its
type and its Mnesia ID. Once we know its decoded form, we have a
helper routine which carries out the actual load. The loader asks the
database to load data, and also verifies the allowed types if needed.

[[db-loading]]
==== DB Loading

The database code contains a way to fetch various objects from the
database and return in a GraphQL friendly representation. First, we
have a translator, which can tell us what a given GraphQL type points
to in the database

[source,erlang]
----
include::{sw_core}/src/sw_core_db.erl[tags=recordOf]
----

This may seem a bit redundant, but in a larger system it is common to
have GraphQL objects backed by several data stores. In this case, the
mapping also becomes a data source router which tells the system where
to go and fetch a given piece of data. Another common case is that the
naming in the database does not match the naming in the GraphQL
schema. In general, see the section <<non-isomorphism>>.

The data loader presented here uses a Mnesia transaction to load the
data. It should be of no surprise to a reader who knows a bit about
Mnesia:

[source,erlang]
----
...
include::{sw_core}/src/sw_core_db.erl[tags=load]
----

For a load this simple, the transaction is probably overkill in
Mnesia. A dirty read could probably have been used instead, and if you
need to handle extreme amounts of data, you might want to avoid the
transaction code and just do a dirty read. For this example though, we
keep things straight and use transactions all over the place to make
the interface more consistent.

==== Loading Complex objects

In the example with the *Planet* above, the loading of the data set is
straightforward because one database row corresponds to one object in
the Graph. For a *Starship* however, The data is spread over multiple
rows. Most of the data lives in a `#transport{}` record and a small
set of additional data lives in a `#starship{}` record. This
corresponds to our earlier handling the schema: most data lives in the
*Transport* interface and a *Starship* implements the transport.

To load a *Starship*, we extend our loader function with a new variant
for loading the starship, and we return the pair of a transport and a
starship as the object:

[source,erlang]
----
include::{sw_core}/src/sw_core_db.erl[tags=loadStarship]
...
----

NOTE: The loading of the *Starship* exemplifies a common trait of
GraphQL systems in which they analyze the object the client wants and
then translate the demand into a series of data acquisition commands.
The data can live in many different locations and can be complex
objects which are mixed together to form the GraphQL type for that
object. This allows the server freedom to choose how it represents
data and what data sources it uses to assemble the response for a
request.

[[walking-in-the-graph]]
=== Walking in the Graph

The specification of a Planet contains a field `residentConnection`
which links the planet to the residents on the planet. To handle such
a link in the code, we begin by implementing the code that tells GraphQL
how to render a *Person*. It follows the same structure as a Planet
from above, and there is little new stuff in those parts.

In the object resolution for the *Planet* we must perform a query in
Mnesia to obtain the relevant persons and then build up the correct
pagination structure.

[source,erlang]
----
execute(_, _, Field, _) ->
    case Field of
        ...;
include::{sw_core}/src/sw_core_planet.erl[tags=residentConnection]
----

We set up a Mnesia transaction through QLC, and then we look for the
people whose homeworld matches our desired Planet ID. Once we have
loaded all such people, we pass them to the pagination system
which slices the data according to the clients specification.

NOTE: Our implementation here is inefficient since it loads every
matching *Person* and _then_ slices it down to the pagination window.
A better way to handle this in a real system would be to ask the
database for the total count and then figure out what the offset and
limit parameters should be to the database. This allows you to request
the window only, which is far more efficient. Real implementations
often bake the pagination into the data fetching in order to achieve
this.

The pagination here follows the {relay} specification for
pagination and is described in the section <<pagination>>.

=== Default Mapping

The module `sw_core_object` contains a _default mapping_ which is the
`execute/4` function used for any object that isn't overridden by a
more specific mapping rule. The implementation is sinisterly simple:

[source,erlang]
----
include::{sw_core}/src/sw_core_object.erl[]
----

The default mapper assumes it is given a `map()` type and then it
looks inside that map for fields. This is convenient because you will
have lots of output types which are plain and simple. You don't want
to invent a specific record for such an object, nor do you want the 
tedium of writing an `execute/4` function for all of them.

As an example the `residentConnection` field we just handled in
<<walking-in-the-graph>> returns an object of type
`ResidentsConnection`. The pagination engine returns a `map()` which
happens to contain precisely the fields of a `ResidentsConnection`.
The default mapper then takes care of everything else if the user
requests fields inside the `ResidentsConnection`.

TIP: You can freely intermingle different representations of objects
on the server side like this example, where we mix `#person{}` records
as well as `map()`'s. This is due to the fact that no value is
returned from GraphQL "`as is`" but always goes through some
`execute/4` function in some module. Exploit this fact to make it
easier to write your own code.

[[resolving-lists]]
=== Resolving lists

A particularly common case is when a type is an array `[T]` of a
certain type `T`. To resolve an array type in GraphQL, you must return
a value in which every object in the list is wrapped in an option
tuple: `{ok, Val} | {error, Reason}`.

Suppose, for instance, we have retrieved three values `A, B, and C`
and the retrieval of the `B` value failed. In this case you would
return

[source,erlang]
----
{ok, [{ok, A}, {error, Reason}, {ok, C}]}
----

to signify that the two values `A` and `C` succeeded but `B` failed. If
the data fetch fails as a whole you can of course fail the full field
by returning `{error, Reason}`.

.Example

In the Star Wars schema, we have a type *Species* for each possible
species in the star wars world. Every *Person* belong to a *Species*.
Since species have a set of possible eye-colors, we have a type
*eyeColors : [String]* in the specification. The `execute/4` function
uses the above rules to generate a list of eye colors:

[source,erlang]
----
include::{sw_core}/src/sw_core_species.erl[tags=execute]
----

Since the result can't fail, we wrap every result in an `{ok, EC}` to
state that every eye colors loaded successfully.

.Alternative representation
****
When we initially built the system, we did not wrap individual objects
in an optional construction. This meant a list load either succeeded 
or failed globally. It created a number of fundamental problems 
because the description isn't precise.

As a result, we made the decision to change the specification to its
current form. While it is a bit more cumbersome to write, it has the
advantage of additional flexibility. You can now discriminate between
`{ok, null}`--There is no value, and that is ok--versus
`{error, Reason}`--there is a problem which isn't handled
appropriately.
****

[[resolution-of-mutations]]
=== Mutations

Object resolution of mutations works the same way as object resolution
for every other kind of type in the graph. When the *Mutation* object
is request in a mutation, the field resolver will run and call an
`execute/4` function for the mutation. In our example, our mutation
code looks like:

[source,erlang]
----
include::{sw_core}/src/sw_core_mutation.erl[tags=execute]
----

We write a generic mutation path. First we unwrap the `input` argument
and then dispatch to a function which handles the `clientMutationId`
entries inside the input. It then calls the actual mutation code in
`execute_mutation` and builds up an appropriate result containing
`clientMutationId` inside the payload.

The reason we do this is due to {relay} and its conventions for
mutations (see <<inputs-and-payloads>>). Because every mutation
contains a mutation id, we can just handle all of them in one go and
then dispatch later on. While here, we also make the input data
cleaner so it is easier for the `execute_mutation` call to work.

TIP: The solution presented here is the beginning of a middleware
stack. See <<middleware-stacks>> for further explanation.

The execution function simply forwards to the target module and then
packs the result in a map so it satisfies the *...Payload* objects.
the idea being that we are then returning something of the correct
type according to the conventions:

[source,erlang]
----
include::{sw_core}/src/sw_core_mutation.erl[tags=executeMutation]
----

The choice of dispatching to modules such as `sw_core_faction` and
`sw_core_starship` is entirely a convention which served us well. For
some GraphQL servers it is better to pick another module for this. As
an example, at {shopgun} we dispatch to a general business logic layer
for mutations rather than handling in the same module as the query
layer. Due to <<cqrs>>, it was easier to build the system in this
fashion.

TIP: Create a convention which works for you and stick to it.
Consistency in your internals are more important than anything else.
The choice you make is worse off if things are not consistent.

==== Mutation-then-query

Note how the GraphQL system will handle a mutation: First field
execution will _mutate_ the data store and then we proceed by field
execution on the returned result. This means that after a mutation we
continue with a _query_. The system runs mutation-then-query. This is
useful for grabbing data out of objects which were changed by the
mutation.

In order to satisfy this, you must have the mutation return valid
objects in the graph as if they had been loaded by a `node(...)` field
say. But often, when you execute a mutation you either create a new
object, or you load, update and persist an object which already
exists. In both situations, you have some contextual objects which you
can return.

=== Mutation Examples

==== Introducing Factions

To create a new faction, the user supplies a `name` in the input as a
parameter. For instance `"rebels"` or `"sith lords"`. To create a new
faction we must execute a transaction in Mnesia which will insert the
faction into the database:

[source,erlang]
----
include::{sw_core}/src/sw_core_faction.erl[tags=introduce]
----
<1> Generate a new unique ID from the database sequences.
<2> Create the newly formed faction record with name and id.
<3> Write the faction record to the database (the record type
    determines the table).
<4> Return the created `#faction{}` record so the system can continue
    by query on the record.

[[introducing-starships]]
==== Introducing Starships

To create a new starship, we generally follow the same pattern as for
faction introduction. However, in this case the introduction is a bit
more complex as there are more work to be done in the process:

[source,erlang]
----
include::{sw_core}/src/sw_core_starship.erl[tags=introduce]
----
<1> Generate a new ID entry from the database sequence.
<2> We generate the `#transport{}` and `#starship{}` records and fill
    in data according to where the data belong. They share the ID.
<3> We decode the *Faction* ID to obtain the underlying database
    primary key.
<4> Load the faction from the database and fail if it is not present.
<5> Supply the Factions Primary Key in the transport to relate them.
<6> Return both the *Faction* and *Starship*.

In our schema, transports and starships share the same primary key id.
So we use the transport sequence to obtain a new ID, using it in both
the transport and starship records. Were we to add vehicles, the same
would happen, but with transport and vehicle respectively.

The decoding of faction IDs assumes that the faction ID can be decoded
and crashes otherwise. A more complete implementation would fail if
this were not the case. A more complete implementation would also fold
the decoding into the call `sw_core_db:load/2` to avoid the explicit
decoding in every object resolution function.

When you have loaded objects in the context, it is customary to return
those in GraphQL. Loading objects is usually where most of the effort
is spent by the system, so returning them is almost free. If the
client doesn't need the object, the client will not request the object
and it won't cost bandwidth in data transfer.

TIP: The example here describes a typical invocation: load the objects
you operate on and make sure every object is valid. Then use
<<authorization>> in the `_Ctx` to check if the desired operation is
valid on the object. Next, execute a transaction and if successful,
return all the loaded objects in the *...Payload* result. This
load-then-auth-then-txn invocation is very common in GraphQL.

=== Anatomy of a query

We now turn our attention to the notion of executing a query. It is
instructional because it explains how a query is executed in the
GraphQL system while using the parts we have defined up until now.

Suppose we look at a query such as the following

[source,graphql]
----
query PlanetQuery {
  node(id: "UGxhbmV0OjI=") {
    ...PlanetFragment
  }
}

fragment PlanetFragment on Planet {
  name
  climate
}
----

and look at how the system will execute such a query.

First, a cursor will be set in the _root_ of the currently selected
`Query` object in the Graph. Since this is mapped by the schema into
the module `sw_core_query`, we start by visiting that module and
execute fields there. The cursor will point to an _initial object_ of
the query, which is set by the developer. We will ignore this object
in our implementation.

Next, since the field `node` is requested, we execute the call

[source,erlang]
----
sw_core_query:execute(Ctx, Obj,
  <<"node">>, #{ <<"id">> => <<"UGxhbmV0OjI=">> }),
----

which will execute `sw_core_db:load/2` on the Starship we requested.
The value returned is the value `{ok, #planet{} = Planet}` for the
planet we requested.

Now, because the type of the `node` field is *Node*, the system will
know that it has loaded something of _interface_ type. Such a type is
abstract and must be made concrete. Thus we use <<type-resolution>>
and a call

[source,erlang]
----
sw_core_type:execute(#planet{} = Planet),
----

is performed. This call will return `{ok, 'Planet'}` as the value.
So the system knows that it can proceed by assuming the *Node* was
really a *Planet*.

The cursor now moves to the planet value and this becomes the new
object of the query. Field resolution and fragment expansion for the
planet object now begins. Calls to `sw_core_planet:execute/4` are
made 3 times for the fields `id`, `name` and `climate`. Our projection
functions return values inside the planet, and this becomes part of
the GraphQL response to the client.

---

To recap: the GraphQL system drives the query and makes callbacks at
appropriate times to your resolver function in order to satisfy the
query. You only have to implement the callbacks. The looping itself is
handled by GraphQL.


